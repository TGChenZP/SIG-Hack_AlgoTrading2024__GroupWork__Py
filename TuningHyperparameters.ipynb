{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from collections import defaultdict\n",
    "\n",
    "from statsmodels.regression.linear_model import OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingStrategy:\n",
    "\n",
    "    def __init__(self, suspension_lookback, suspension_days, sign_change_threshold, wrong_sign_threshold, stop_loss_lookback, stop_loss_size_factor, build_period):\n",
    "\n",
    "        self.SUSPENSION_LOOKBACK = suspension_lookback\n",
    "        self.SIGN_CHANGE_THRESHOLD = sign_change_threshold\n",
    "        self.SUSPENSION_DAYS = suspension_days\n",
    "        self.WRONG_SIGN_THRESHOLD = wrong_sign_threshold\n",
    "        self.STOP_LOSS_LOOKBACK = stop_loss_lookback\n",
    "        self.STOP_LOSS_SIZE_FACTOR = stop_loss_size_factor\n",
    "        self.BUILD_PERIOD = build_period\n",
    "\n",
    "        self.features = ['close_to_close (t-5)(t0)']\n",
    "        self.TARGET_COLUMN = ''\n",
    "        self.FIVE_DAY_TARGET_COLUMN = 'forward_5_'\n",
    "\n",
    "        self.NUM_STOCKS = 50\n",
    "        self.TEST_LENGTH = 250\n",
    "        self.TRAIN_LENGTH = 250\n",
    "    \n",
    "    def exp_growth(self, x, a=500, b= 0.00013863, c=0):\n",
    "        return a * np.exp(b * x) + c\n",
    "\n",
    "    def build_multivariate_linear_regression(self, log_return_df, target_stock, feature_stock, features, test_start_date, train_length, target_column):\n",
    "\n",
    "        data = log_return_df[[f'{target_column}{target_stock}']+[f'{_}_{target_stock}' for _ in features]+[f'{_}_{feature_stock}' for _ in features]].iloc[test_start_date-train_length:test_start_date]\n",
    "        if target_stock == feature_stock:\n",
    "            data = log_return_df[[f'{target_column}{target_stock}']+[f'{_}_{target_stock}' for _ in features]].iloc[test_start_date-train_length:test_start_date]\n",
    "        data.dropna(inplace=True)\n",
    "\n",
    "        y = data[f'{target_column}{target_stock}']\n",
    "        X = data.drop(columns=[f'{target_column}{target_stock}'])\n",
    "        X = X.assign(const=1)\n",
    "\n",
    "        # build models\n",
    "        model = OLS(y, X).fit()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def inference_multivariate_linear_regression(self, log_return_df, model, target_stock, feature_stock, features):\n",
    "        \n",
    "        X = log_return_df[[f'{_}_{target_stock}' for _ in features]+[f'{_}_{feature_stock}' for _ in features]].iloc[-1:]\n",
    "        if target_stock == feature_stock:\n",
    "            X = log_return_df[[f'{_}_{target_stock}' for _ in features]].iloc[-1:]\n",
    "\n",
    "        X = X.assign(const=1)\n",
    "        \n",
    "        pred_t1 = model.predict(X).values[0]\n",
    "\n",
    "        return pred_t1\n",
    "\n",
    "    def predict_train_multivariate(self, log_return_df, model, target_stock, feature_stock, features, test_start_date, train_length, target_column):\n",
    "        \n",
    "        data = log_return_df[[f'{target_column}{target_stock}']+[f'{_}_{target_stock}' for _ in features]+[f'{_}_{feature_stock}' for _ in features]].iloc[test_start_date-train_length:test_start_date]\n",
    "        if target_stock == feature_stock:\n",
    "            data = log_return_df[[f'{target_column}{target_stock}']+[f'{_}_{target_stock}' for _ in features]].iloc[test_start_date-train_length:test_start_date]\n",
    "        data.dropna(inplace=True)\n",
    "\n",
    "        y = data[f'{target_column}{target_stock}']\n",
    "        X = data.drop(columns=[f'{target_column}{target_stock}'])\n",
    "        X = X.assign(const=1)\n",
    "\n",
    "        y_pred = model.predict(X)\n",
    "        \n",
    "        return y, y_pred\n",
    "\n",
    "    def build_models_for_this_period(self, log_return_df, test_start_date, features, train_length, target_column):\n",
    "\n",
    "        good_model_dict = defaultdict(dict)\n",
    "        model_accuracy_dict = defaultdict(dict)\n",
    "        model_features_dict = defaultdict(dict)\n",
    "\n",
    "        for i in range(self.NUM_STOCKS):\n",
    "            for j in range(self.NUM_STOCKS+1):\n",
    "                \n",
    "                ma_model = self.build_multivariate_linear_regression(log_return_df, i, j, features, test_start_date, train_length, target_column)\n",
    "                ma_y, ma_pred = self.predict_train_multivariate(log_return_df, ma_model, i, j, features, test_start_date, train_length, target_column)\n",
    "\n",
    "                if abs(ma_model.tvalues.values[0]) >= 2 or abs(ma_model.tvalues.values[len(features)]//2) >= 2:\n",
    "                    good_model_dict[i][j] = ma_model\n",
    "                    model_features_dict[i][j] = features\n",
    "                    model_accuracy_dict[i][j] = accuracy_score(np.sign(ma_y), np.sign(ma_pred))\n",
    "\n",
    "        final_model_dict = defaultdict(dict)\n",
    "\n",
    "        for stock_i in model_accuracy_dict:\n",
    "            top_10 = sorted(model_accuracy_dict[stock_i].items(), key=lambda x: x[1], reverse=True)\n",
    "            for stock_j, score in top_10:\n",
    "                \n",
    "                if stock_j in good_model_dict[stock_i]: # Todo: in future take average, or take average of votes?\n",
    "                    final_model_dict[stock_i][stock_j] = good_model_dict[stock_i][stock_j]  \n",
    "\n",
    "        return final_model_dict, model_features_dict\n",
    "    \n",
    "    def get_suspension_signals(self, log_return_df, prcSoFar, stock_i, START_DATE, SUSPENSION_LOOKBACK, signals):\n",
    "        lookback_returns = log_return_df[str(stock_i)].iloc[-SUSPENSION_LOOKBACK-1:-1].tolist() # get last 10 days of return\n",
    "        # get 10 day sign flip\n",
    "        last_n_return_sign_changes = sum(np.sign(lookback_returns[i]) != np.sign(lookback_returns[i-1]) for i in range(1, len(lookback_returns)))\n",
    "\n",
    "        # get accuracy\n",
    "        # get number of signal different sign to last 10 days\n",
    "        lookback_signals = signals[stock_i, prcSoFar.shape[1]-START_DATE-SUSPENSION_LOOKBACK:prcSoFar.shape[1]-START_DATE]\n",
    "        wrong_sign = sum(lookback_signals[i] != 0 and np.sign(lookback_signals[i]) != np.sign(lookback_returns[i]) for i in range(len(lookback_signals)))\n",
    "\n",
    "        return last_n_return_sign_changes, wrong_sign\n",
    "\n",
    "    def apply_suspension(self, last_n_return_sign_changes, wrong_sign, SUSPENSION_LOOKBACK, SUSPENSION_DAYS, SIGN_CHANGE_THRESHOLD, WRONG_SIGN_THRESHOLD, suspension_days, suspension_activated, stock_i, START_DATE, prcSoFar):\n",
    "        \n",
    "        if last_n_return_sign_changes/SUSPENSION_LOOKBACK >= SIGN_CHANGE_THRESHOLD or wrong_sign/SUSPENSION_LOOKBACK >= WRONG_SIGN_THRESHOLD:\n",
    "            suspension_days[stock_i] = SUSPENSION_DAYS # ban for 3 days\n",
    "            suspension_activated[stock_i, prcSoFar.shape[1]-START_DATE] = 1\n",
    "            \n",
    "        return suspension_days, suspension_activated\n",
    "\n",
    "    def get_stop_loss_signals(self, currentPos, log_return_df, stock_i, STOP_LOSS_LOOKBACK, final_model_dict_5, model_features_dict_5):\n",
    "        # get sum of sign of last 2 days\n",
    "        stop_loss_lookback_return = np.sum(np.sign(log_return_df[str(stock_i)].iloc[-STOP_LOSS_LOOKBACK-1:-1].tolist())) \n",
    "\n",
    "        # get current position sign\n",
    "        stock_i_curr_pos_sign = np.sign(currentPos[stock_i])\n",
    "\n",
    "        # get 5 days prediction\n",
    "        stock_i_predictions_list_5 = []\n",
    "        for stock_j in final_model_dict_5[stock_i]:\n",
    "            stock_i_predictions_list_5.append(self.inference_multivariate_linear_regression(log_return_df,\n",
    "                                    final_model_dict_5[stock_i][stock_j],\n",
    "                                    stock_i,\n",
    "                                    stock_j,\n",
    "                                    model_features_dict_5[stock_i][stock_j]))\n",
    "        \n",
    "        stock_i_prediction_5 = np.sign(np.sum([np.sign(x) for x in stock_i_predictions_list_5]))\n",
    "\n",
    "        return stop_loss_lookback_return, stock_i_curr_pos_sign, stock_i_prediction_5\n",
    "\n",
    "    def apply_stop_loss(self, stop_loss_lookback_return, stock_i_prediction_5, stock_i_curr_pos_sign, STOP_LOSS_LOOKBACK, STOP_LOSS_SIZE_FACTOR, currentPos, prcSoFar, START_DATE, stop_loss_activated, stock_i):\n",
    "        stop_loss_today = False\n",
    "\n",
    "        if stop_loss_lookback_return == -STOP_LOSS_LOOKBACK and stock_i_prediction_5 == -1 and stock_i_curr_pos_sign == 1:\n",
    "            currentPos[stock_i] -= STOP_LOSS_SIZE_FACTOR * self.exp_growth(abs(currentPos[stock_i]*prcSoFar[stock_i, -1]))/prcSoFar[stock_i, -1]\n",
    "            stop_loss_today = True\n",
    "            stop_loss_activated[stock_i, prcSoFar.shape[1]-START_DATE] = 1\n",
    "        elif stop_loss_lookback_return == STOP_LOSS_LOOKBACK and stock_i_prediction_5 == 1 and stock_i_curr_pos_sign == -1:\n",
    "            currentPos[stock_i] += STOP_LOSS_SIZE_FACTOR * self.exp_growth(abs(currentPos[stock_i]*prcSoFar[stock_i, -1]))/prcSoFar[stock_i, -1]\n",
    "            stop_loss_today = True\n",
    "            stop_loss_activated[stock_i, prcSoFar.shape[1]-START_DATE] = 1\n",
    "        \n",
    "        return currentPos, stop_loss_today, stop_loss_activated\n",
    "\n",
    "    def get_signals(self, log_return_df, final_model_dict, stock_i, model_features_dict, signals, prcSoFar, START_DATE):\n",
    "        \n",
    "        stock_i_predictions_list = []\n",
    "        for stock_j in final_model_dict[stock_i]:\n",
    "            stock_i_predictions_list.append(self.inference_multivariate_linear_regression(log_return_df,\n",
    "                                    final_model_dict[stock_i][stock_j],\n",
    "                                    stock_i,\n",
    "                                    stock_j,\n",
    "                                    model_features_dict[stock_i][stock_j]))\n",
    "\n",
    "            \n",
    "        stock_i_prediction = np.sign(np.sum([np.sign(x) for x in stock_i_predictions_list]))\n",
    "\n",
    "        signals[stock_i, prcSoFar.shape[1]-START_DATE] = stock_i_prediction\n",
    "\n",
    "        return stock_i_prediction, signals\n",
    "\n",
    "    def update_position_for_stock(self, stock_i_prediction, currentPos, stock_i, prcSoFar):\n",
    "        if stock_i_prediction > 0:\n",
    "            currentPos[stock_i] += self.exp_growth(10000-abs(currentPos[stock_i]*prcSoFar[stock_i, -1]))/prcSoFar[stock_i, -1]\n",
    "        elif stock_i_prediction < -0:\n",
    "            currentPos[stock_i] -= self.exp_growth(10000-abs(currentPos[stock_i]*prcSoFar[stock_i, -1]))/prcSoFar[stock_i, -1]\n",
    "        \n",
    "        return currentPos\n",
    "\n",
    "    def getMyPosition(self, prcSoFar):\n",
    "    \n",
    "        global currentPos, \\\n",
    "                final_model_dict, \\\n",
    "                model_features_dict, \\\n",
    "                test_start_date, \\\n",
    "                signals, \\\n",
    "                suspension_days, \\\n",
    "                stop_loss_activated, \\\n",
    "                suspension_activated, \\\n",
    "                final_model_dict_5, \\\n",
    "                model_features_dict_5\n",
    "        \n",
    "        # last day don't make any new positions\n",
    "        if prcSoFar.shape[1] == self.START_DATE+250: \n",
    "            return currentPos\n",
    "\n",
    "        # feature engineered data\n",
    "        log_return_df = self.feature_engineer(prcSoFar)\n",
    "\n",
    "        # first day train the models\n",
    "        if prcSoFar.shape[1] % self.TEST_LENGTH == 0:\n",
    "\n",
    "            currentPos = np.zeros(nInst)\n",
    "\n",
    "            # get structures for reporting\n",
    "            signals = np.zeros([50, 251])\n",
    "            suspension_activated = np.zeros([50, 251])\n",
    "            stop_loss_activated = np.zeros([50, 251])\n",
    "\n",
    "            # structure to record days of suspension for each model \n",
    "            suspension_days = defaultdict(int)\n",
    "\n",
    "            # get the first date for test period\n",
    "            test_start_date = prcSoFar.shape[1]\n",
    "\n",
    "            # train models\n",
    "            final_model_dict, model_features_dict = self.build_models_for_this_period(log_return_df, test_start_date, self.features, self.TRAIN_LENGTH, self.TARGET_COLUMN)\n",
    "            final_model_dict_5, model_features_dict_5 = self.build_models_for_this_period(log_return_df, test_start_date, self.features, self.TRAIN_LENGTH, self.FIVE_DAY_TARGET_COLUMN)\n",
    "\n",
    "        for stock_i in final_model_dict:\n",
    "\n",
    "            stop_loss_today = False\n",
    "\n",
    "            if prcSoFar.shape[1] >= self.START_DATE + self.BUILD_PERIOD: # skip first couple of days\n",
    "                \n",
    "                # MODEL SUSPENSION\n",
    "                last_n_return_sign_changes, wrong_sign = self.get_suspension_signals(log_return_df, prcSoFar, stock_i, self.START_DATE, self.SUSPENSION_LOOKBACK, signals)\n",
    "                suspension_days, suspension_activated = self.apply_suspension(last_n_return_sign_changes, wrong_sign, self.SUSPENSION_LOOKBACK, self.SUSPENSION_DAYS, self.SIGN_CHANGE_THRESHOLD, self.WRONG_SIGN_THRESHOLD, suspension_days, suspension_activated, stock_i, self.START_DATE, prcSoFar)\n",
    "\n",
    "                # STOP LOSS\n",
    "                stop_loss_lookback_return, stock_i_curr_pos_sign, stock_i_prediction_5 = self.get_stop_loss_signals(currentPos, log_return_df, stock_i, self.STOP_LOSS_LOOKBACK, final_model_dict_5, model_features_dict_5)\n",
    "                currentPos, stop_loss_today, stop_loss_activated = self.apply_stop_loss(stop_loss_lookback_return, stock_i_prediction_5, stock_i_curr_pos_sign, self.STOP_LOSS_LOOKBACK, self.STOP_LOSS_SIZE_FACTOR, currentPos, prcSoFar, self.START_DATE, stop_loss_activated, stock_i)\n",
    "\n",
    "            # OPEN POSITION WITH MODEL\n",
    "            stock_i_prediction, signals = self.get_signals(log_return_df, final_model_dict, stock_i, model_features_dict, signals, prcSoFar, self.START_DATE) \n",
    "\n",
    "            # consider suspension and stop loss, then adjust position\n",
    "            if suspension_days[stock_i] > 0: # model suspended\n",
    "                suspension_days[stock_i] -= 1\n",
    "            elif stop_loss_today: # stop loss, don't use model to open position\n",
    "                pass \n",
    "            else: # update the position\n",
    "                currentPos = self.update_position_for_stock(stock_i_prediction, currentPos, stock_i, prcSoFar)\n",
    "\n",
    "            # clip to 10k\n",
    "            currentPos[stock_i] = np.clip(currentPos[stock_i], -10000/prcSoFar[stock_i, -1], 10000/prcSoFar[stock_i, -1])\n",
    "\n",
    "        return currentPos\n",
    "    \n",
    "    def get_log_returns(self, prices):\n",
    "        # get log_returns\n",
    "        # put into pandas\n",
    "        prices_df = pd.DataFrame(prices).T\n",
    "        # turn into log returns\n",
    "        log_return_df = prices_df.pct_change().apply(lambda x: np.log(1+x)).shift(-1)\n",
    "\n",
    "        for ma in [5]:\n",
    "            for stock_i in range(self.NUM_STOCKS+1):\n",
    "                log_return_df[f'forward_{ma}_{stock_i}'] = np.log(prices_df[stock_i]/prices_df[stock_i].shift(ma)).shift(-ma)\n",
    "                log_return_df[f'close_to_close (t-{ma})(t0)_'+str(stock_i)] = np.log(prices_df[stock_i]/prices_df[stock_i].shift(ma))\n",
    "                \n",
    "        # for ma in [1, 5]:\n",
    "        #     for stock_i in range(nInst):\n",
    "        #         for stock_j in range(stock_i+1, nInst):\n",
    "        #             log_return_df[f'diff_forward_{ma}_{stock_i}_{stock_j}'] = log_return_df[f'forward_{ma}_{stock_i}'] - log_return_df[f'forward_{ma}_{stock_j}']\n",
    "                    # log_return_df[f'diff_close_to_close (t-{ma})(t0)_'+str(stock_i)+'_'+str(stock_j)] = log_return_df[f'close_to_close (t-{ma})(t0)_{stock_i}'] - log_return_df[f'close_to_close (t-{ma})(t0)_{stock_j}']\n",
    "\n",
    "        return log_return_df\n",
    "    \n",
    "    def feature_engineer(self, prices):\n",
    "    \n",
    "        # add market which is the mean of all returns\n",
    "        prices = np.vstack((prices, prices.mean(axis=0)))\n",
    "\n",
    "        log_return_df = self.get_log_returns(prices)\n",
    "        # feature engineering\n",
    "\n",
    "        # for stock_id in range(nInst+1):\n",
    "            # create lags\n",
    "            # log_return_df['lag1_'+str(stock_id)] = log_return_df[stock_id].shift(1)\n",
    "            # log_return_df['lag2_'+str(stock_id)] = log_return_df[stock_id].shift(2)\n",
    "            \n",
    "            # create MA\n",
    "            # log_return_df['ma5_'+str(stock_id)] = log_return_df[stock_id].rolling(window=5).mean().shift(1)\n",
    "            # log_return_df['ma10_'+str(stock_id)] = log_return_df[stock_id].rolling(window=10).mean().shift(1)\n",
    "            # log_return_df['ma20_'+str(stock_id)] = log_return_df[stock_id].rolling(window=20).mean().shift(1)\n",
    "\n",
    "        log_return_df.rename(columns={stock_id:str(stock_id) for stock_id in range(self.NUM_STOCKS+1)}, inplace=True)\n",
    "            \n",
    "        return log_return_df\n",
    "\n",
    "    def predict(self, prcHist, period_start_date):\n",
    "\n",
    "        self.START_DATE = period_start_date\n",
    "\n",
    "        nInst = 50\n",
    "\n",
    "        commRate = 0.0010\n",
    "        dlrPosLimit = 10000\n",
    "\n",
    "        self.currentPos = np.zeros(nInst)\n",
    "        self.yesterday_sign = np.zeros(nInst)\n",
    "\n",
    "        cash = 0\n",
    "        curPos = np.zeros(nInst)\n",
    "        totDVolume = 0\n",
    "        value = 0\n",
    "        todayPLL = []\n",
    "        (_,nt) = prcHist.shape\n",
    "        for t in range(period_start_date, period_start_date+251): \n",
    "            prcHistSoFar = prcHist[:,:t]\n",
    "            newPosOrig = self.getMyPosition(prcHistSoFar)\n",
    "            curPrices = prcHistSoFar[:,-1] #prcHist[:,t-1]\n",
    "            posLimits = np.array([int(x) for x in dlrPosLimit / curPrices])\n",
    "            clipPos = np.clip(newPosOrig, -posLimits, posLimits)\n",
    "            newPos = np.array([np.trunc(x) for x in clipPos])\n",
    "            deltaPos = newPos - curPos\n",
    "            dvolumes = curPrices * np.abs(deltaPos)\n",
    "            dvolume = np.sum(dvolumes)\n",
    "            totDVolume += dvolume\n",
    "            comm = dvolume * commRate\n",
    "            cash -= curPrices.dot(deltaPos) + comm\n",
    "            curPos = np.array(newPos)\n",
    "            posValue = curPos.dot(curPrices)\n",
    "            todayPL = cash + posValue - value\n",
    "            todayPLL.append(todayPL)\n",
    "            value = cash + posValue\n",
    "            ret = 0.0\n",
    "            if (totDVolume > 0):\n",
    "                ret = value / totDVolume\n",
    "        pll = np.array(todayPLL)\n",
    "        (plmu,plstd) = (np.mean(pll), np.std(pll))\n",
    "        annSharpe = 0.0\n",
    "        if (plstd > 0):\n",
    "            annSharpe = np.sqrt(250) * plmu / plstd\n",
    "        \n",
    "        return plmu - 0.1*plstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPrices(fn):\n",
    "    global nt, nInst\n",
    "    df=pd.read_csv(fn, sep='\\s+', header=None, index_col=None)\n",
    "    nt, nInst = df.values.shape\n",
    "    return (df.values).T\n",
    "\n",
    "data = loadPrices('./prices.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuner_Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class JiaoCheng:\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Initialise class \"\"\"\n",
    "        self._initialise_objects()\n",
    "\n",
    "        print('JiaoCheng Initialised')\n",
    "\n",
    "\n",
    "\n",
    "    def _initialise_objects(self):\n",
    "        \"\"\" Helper to initialise objects \"\"\"\n",
    "\n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "        self.val_x = None\n",
    "        self.val_y = None\n",
    "        self.test_x = None\n",
    "        self.test_y = None\n",
    "        self.tuning_result = None\n",
    "        self.model = None\n",
    "        self.parameter_choices = None\n",
    "        self.hyperparameters = None\n",
    "        self.feature_n_ningxiang_score_dict = None\n",
    "        self.non_tuneable_parameter_choices = list()\n",
    "        self._feature_combo_n_index_map = None\n",
    "        self.checked = None\n",
    "        self.result = None\n",
    "        self.tuning_result_saving_address = None\n",
    "        self.object_saving_address = None\n",
    "        self._up_to = 0\n",
    "        self._tune_features = False\n",
    "        self._seed = 19210216\n",
    "        self.best_score = -np.inf\n",
    "        self.best_combo = None\n",
    "        self.best_clf = None\n",
    "        self.clf_type = None\n",
    "        self.combos = None\n",
    "        self.n_items = None\n",
    "        self.hyperparameter_tuning_order = None\n",
    "        self._tuning_order_map_hp = None\n",
    "        self._parameter_value_map_index = None\n",
    "        self._total_combos = None\n",
    "        self._tune_features = False\n",
    "        self.hyperparameter_default_values = None\n",
    "        self.best_model_saving_address = None\n",
    "\n",
    "        self.regression_extra_output_columns = ['Train r2', 'Val r2', 'Test r2', \n",
    "            'Train RMSE', 'Val RMSE', 'Test RMSE', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Time']\n",
    "        self.classification_extra_output_columns = ['Train accu', 'Val accu', 'Test accu', \n",
    "            'Train balanced_accu', 'Val balanced_accu', 'Test balanced_accu', 'Train f1', 'Val f1', 'Test f1', \n",
    "            'Train precision', 'Val precision', 'Test precision', 'Train recall', 'Val recall', 'Test recall', 'Time']\n",
    "\n",
    "        \n",
    "\n",
    "    def read_in_data(self, data):\n",
    "        \"\"\" Reads in train validate test data for tuning \"\"\"\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_model(self, model, type):\n",
    "        \"\"\" Reads in underlying model object for tuning, and also read in what type of model it is \"\"\"\n",
    "\n",
    "        assert type == 'Classification' or type == 'Regression' # check\n",
    "\n",
    "        # record\n",
    "        self.model = model\n",
    "        self.clf_type = type \n",
    "\n",
    "        print(f'Successfully read in model {self.model}, which is a {self.clf_type} model')\n",
    "\n",
    "\n",
    "\n",
    "    def set_hyperparameters(self, parameter_choices):\n",
    "        \"\"\" Input hyperparameter choices \"\"\"\n",
    "\n",
    "        self.parameter_choices = parameter_choices\n",
    "        self._sort_hyperparameter_choices()\n",
    "\n",
    "        self.param_value_reverse_map = {param:{self.parameter_choices[param][j]:j for j in range(len(self.parameter_choices[param]))} for param in self.parameter_choices}\n",
    "\n",
    "        self.hyperparameters = list(parameter_choices.keys())\n",
    "\n",
    "        # automatically calculate how many different values in each hyperparameter\n",
    "        self.n_items = [len(parameter_choices[key]) for key in self.hyperparameters]\n",
    "        self._total_combos = np.prod(self.n_items)\n",
    "\n",
    "        # automatically calculate all combinations and setup checked and result arrays and tuning result dataframe\n",
    "        self._get_combinations()\n",
    "        self._get_checked_and_result_array()\n",
    "        self._setup_tuning_result_df()\n",
    "\n",
    "        print(\"Successfully recorded hyperparameter choices\")\n",
    "\n",
    "\n",
    "\n",
    "    def _sort_hyperparameter_choices(self):\n",
    "        \"\"\" Helper to ensure all hyperparameter choice values are in order from lowest to highest \"\"\"\n",
    "\n",
    "        for key in self.parameter_choices:\n",
    "            tmp = copy.deepcopy(list(self.parameter_choices[key]))\n",
    "            tmp.sort()\n",
    "            self.parameter_choices[key] = tuple(tmp)\n",
    "\n",
    "    \n",
    "\n",
    "    def _get_combinations(self):\n",
    "        \"\"\" Helper to calculate all combinations \"\"\"\n",
    "\n",
    "        ##ALGORITHM\n",
    "\n",
    "        # recursively append values to get every combination in ordinal/numerical form\n",
    "        self.combos = [[]]\n",
    "        for i in range(len(self.n_items)):\n",
    "\n",
    "            tmp = copy.deepcopy(self.combos)\n",
    "            self.combos = list()\n",
    "\n",
    "            for x in tmp:\n",
    "\n",
    "                for k in range(self.n_items[i]):\n",
    "                    y = copy.deepcopy(x)\n",
    "                    \n",
    "                    y.append(k)\n",
    "\n",
    "                    self.combos.append(y)\n",
    "\n",
    "\n",
    "\n",
    "    def _get_checked_and_result_array(self):\n",
    "        \"\"\" Helper to set up checked and result array \"\"\"\n",
    "\n",
    "        self.checked = np.zeros(shape=self.n_items)\n",
    "        self.result = np.zeros(shape=self.n_items)\n",
    "\n",
    "\n",
    "\n",
    "    def _setup_tuning_result_df(self):\n",
    "        \"\"\" Helper to set up tuning result dataframe \"\"\"\n",
    "\n",
    "        tune_result_columns = copy.deepcopy(self.hyperparameters)\n",
    "\n",
    "        if self._tune_features == True:\n",
    "            tune_result_columns.append('feature combo ningxiang score')\n",
    "\n",
    "        # Different set of metric columns for different types of models\n",
    "        if self.clf_type == 'Classification':\n",
    "            tune_result_columns.extend(self.classification_extra_output_columns)\n",
    "        elif self.clf_type == 'Regression':\n",
    "            tune_result_columns.extend(self.regression_extra_output_columns)\n",
    "\n",
    "        self.tuning_result = pd.DataFrame({col:list() for col in tune_result_columns})\n",
    "\n",
    "\n",
    "\n",
    "    def set_non_tuneable_hyperparameters(self, non_tuneable_hyperparameter_choice):\n",
    "        \"\"\" Input Non tuneable hyperparameter choice \"\"\"\n",
    "\n",
    "        if type(non_tuneable_hyperparameter_choice) is not dict:\n",
    "            raise TypeError('non_tuneable_hyeprparameters_choice must be dict, please try again')\n",
    "            \n",
    "        \n",
    "        for nthp in non_tuneable_hyperparameter_choice:\n",
    "            if type(non_tuneable_hyperparameter_choice[nthp]) in (set, list, tuple, dict):\n",
    "                raise TypeError('non_tuneable_hyperparameters_choice must not be of array-like type')\n",
    "                \n",
    "\n",
    "        self.non_tuneable_parameter_choices = non_tuneable_hyperparameter_choice\n",
    "\n",
    "        print(\"Successfully recorded non_tuneable_hyperparameter choices\")\n",
    "\n",
    "\n",
    "\n",
    "    def set_features(self, ningxiang_output):\n",
    "        \"\"\" Input features \"\"\"\n",
    "\n",
    "        if type(ningxiang_output) is not dict:\n",
    "            raise TypeError(\"Please ensure NingXiang output is a dict\")\n",
    "            \n",
    "        \n",
    "        if not self.hyperparameters:\n",
    "            raise AttributeError(\"Missing hyperparameter choices, please run .set_hyperparameters() first\")\n",
    "            \n",
    "        \n",
    "        for feature in list(ningxiang_output.keys())[-1]:\n",
    "            if feature not in list(self.train_x.columns):\n",
    "                raise ValueError(f'feature {feature} in ningxiang output is not in train_x. Please try again')\n",
    "                \n",
    "            if feature not in list(self.val_x.columns):\n",
    "                raise ValueError(f'feature {feature} in ningxiang output is not in val_x. Please try again')\n",
    "                \n",
    "            if feature not in list(self.test_x.columns):\n",
    "                raise ValueError(f'feature {feature} in ningxiang output is not in test_x. Please try again')\n",
    "                \n",
    "        \n",
    "        # sort ningxiang just for safety, and store up\n",
    "        ningxiang_output_sorted = self._sort_features(ningxiang_output)\n",
    "        self.feature_n_ningxiang_score_dict = ningxiang_output_sorted\n",
    "\n",
    "        # activate this switch\n",
    "        self._tune_features = True\n",
    "\n",
    "        # update previous internal structures based on first set of hyperparameter choices\n",
    "        ##here used numbers instead of tuples as the values in parameter_choices; thus need another mapping to get map back to the features\n",
    "        self.parameter_choices['features'] = tuple([i for i in range(len(ningxiang_output_sorted))])\n",
    "        self._feature_combo_n_index_map = {i: list(ningxiang_output_sorted.keys())[i] for i in range(len(ningxiang_output_sorted))}\n",
    "\n",
    "        self.param_value_reverse_map = {param:{self.parameter_choices[param][j]:j for j in range(len(self.parameter_choices[param]))} for param in self.parameter_choices}\n",
    "        \n",
    "        self.hyperparameters = list(self.parameter_choices.keys())\n",
    "\n",
    "        # automatically calculate how many different values in each hyperparameter\n",
    "        self.n_items = [len(self.parameter_choices[key]) for key in self.hyperparameters]\n",
    "        self._total_combos = np.prod(self.n_items)\n",
    "\n",
    "        # automatically calculate all combinations and setup checked and result arrays and tuning result dataframe\n",
    "        self._get_combinations()\n",
    "        self._get_checked_and_result_array()\n",
    "        self._setup_tuning_result_df()\n",
    "\n",
    "        print(\"Successfully recorded tuneable feature combination choices and updated relevant internal structures\")\n",
    "\n",
    "\n",
    "    \n",
    "    def _sort_features(self, ningxiang_output):\n",
    "        \"\"\" Helper for sorting features based on NingXiang values (input dict output dict) \"\"\"\n",
    "\n",
    "        ningxiang_output_list = [(key, ningxiang_output[key]) for key in ningxiang_output]\n",
    "\n",
    "        ningxiang_output_list.sort(key = lambda x:x[1])\n",
    "\n",
    "        ningxiang_output_sorted = {x[0]:x[1] for x in ningxiang_output_list}\n",
    "\n",
    "        return ningxiang_output_sorted\n",
    "\n",
    "\n",
    "    \n",
    "    def set_tuning_order(self, order):\n",
    "        \"\"\" Input sorting order \"\"\"\n",
    "        \n",
    "        if type(order) is not list:\n",
    "            raise TypeError(\"order must be a list, please try agian\")\n",
    "            \n",
    "        \n",
    "        if self.hyperparameters == False:\n",
    "            raise AttributeError('Please run set_hyperparameters() first')\n",
    "            \n",
    "        \n",
    "        if 'features' in self.hyperparameters:\n",
    "            if self._tune_features == False:\n",
    "                raise AttributeError('Please run set_features() first')\n",
    "                \n",
    "        \n",
    "        for hp in order:\n",
    "            if hp not in self.hyperparameters:\n",
    "                raise ValueError(f'Feature {hp} is not in self.hyperparameters which was set by set_hyperparameters(); consider reinitiating JiaoCheng or double checking input')\n",
    "                \n",
    "\n",
    "        self.hyperparameter_tuning_order = order\n",
    "        self._tuning_order_map_hp = {self.hyperparameters[i]:i for i in range(len(self.hyperparameters))}\n",
    "    \n",
    "\n",
    "    \n",
    "    def set_hyperparameter_default_values(self, default_values):\n",
    "        \"\"\" Input default values for hyperparameters \"\"\"\n",
    "\n",
    "        if type(default_values) is not dict:\n",
    "            raise TypeError(\"default_values must be a dict, please try agian\")\n",
    "            \n",
    "        \n",
    "        if self.hyperparameters == False:\n",
    "            raise AttributeError('Please run set_hyperparameters() first')\n",
    "            \n",
    "        \n",
    "        if 'features' in self.hyperparameters:\n",
    "            if self._tune_features == False:\n",
    "                raise AttributeError('Please run set_features() first')\n",
    "\n",
    "        \n",
    "        for hp in default_values:\n",
    "            if hp not in self.hyperparameters:\n",
    "                raise ValueError(f'Feature {hp} is not in self.hyperparameter which was set by set_hyperparameters(); consider reinitiating JiaoCheng or double checking input')\n",
    "                \n",
    "            if default_values[hp] not in self.parameter_choices[hp]:\n",
    "                raise ValueError(f'{default_values[hp]} is not a value to try out in self.hyperparameter which was set by set_hyperparameters(). consider reinitiating JiaoCheng or double checking input')\n",
    "                \n",
    "\n",
    "        self.hyperparameter_default_values = default_values\n",
    "\n",
    "\n",
    "        \n",
    "    def tune(self, key_stats_only = False): #TODO\n",
    "        \"\"\" Begin tuning \"\"\"\n",
    "            \n",
    "\n",
    "        if self.model is None:\n",
    "            raise AttributeError(\" Missing model, please run .read_in_model() \")\n",
    "            \n",
    "        \n",
    "        if self.combos is None:\n",
    "            raise AttributeError(\"Missing hyperparameter choices, please run .set_hyperparameters() first\")\n",
    "            \n",
    "\n",
    "        if self.tuning_result_saving_address is None:\n",
    "            raise AttributeError(\"Missing tuning result csv saving address, please run .set_tuning_result_saving_address() first\")\n",
    "\n",
    "        self.key_stats_only = key_stats_only\n",
    "        \n",
    "        \n",
    "        starting_hp_combo = [self.param_value_reverse_map[hp][self.hyperparameter_default_values[hp]] for hp in self.hyperparameters] # setup starting combination\n",
    "        print('\\nDefault combo:', starting_hp_combo, '\\n')\n",
    "\n",
    "        round = 1\n",
    "        continue_tuning = 1 # continuously loop through features until converge (combo stays same after a full round)\n",
    "        while continue_tuning:\n",
    "            print(\"\\nROUND\", round)\n",
    "\n",
    "            # first store previous round's best combo/the starting combo before each round; for comparison at the end\n",
    "            last_round_starting_hp_combo = copy.deepcopy(starting_hp_combo)\n",
    "\n",
    "            for hp in self.hyperparameter_tuning_order: # tune each hp in order\n",
    "                print(\"\\nRound\", round, '\\nHyperparameter:', hp, f'(index: {self._tuning_order_map_hp[hp]})', '\\n')\n",
    "\n",
    "                last_hyperparameter_best_hp_combo = copy.deepcopy(starting_hp_combo) # store last iteration's best combo\n",
    "\n",
    "                combo = list(copy.deepcopy(starting_hp_combo)) # tune the root combo\n",
    "                combo[self._tuning_order_map_hp[hp]] = 0\n",
    "\n",
    "                for i in range(self.n_items[self._tuning_order_map_hp[hp]]):\n",
    "                \n",
    "                    if not self.checked[tuple(combo)]:\n",
    "                        self._up_to += 1\n",
    "                        self._train_and_test_combo(combo)\n",
    "                    else:\n",
    "                        self._check_already_trained_best_score(combo)\n",
    "                      \n",
    "                    combo[self._tuning_order_map_hp[hp]] += 1 \n",
    "                \n",
    "                starting_hp_combo = copy.deepcopy(self.best_combo) # take the best combo after this hyperparameter has been tuned\n",
    "                \n",
    "                if starting_hp_combo == last_hyperparameter_best_hp_combo:\n",
    "                    print('\\nBest combo after this hyperparameter:', starting_hp_combo, ', NOT UPDATED SINCE LAST HYPERPARAMETER\\n')\n",
    "                else:\n",
    "                    print('\\nBest combo after this hyperparameter:', starting_hp_combo, ', UPDATED SINCE LAST HYPERPARAMETER\\n')\n",
    "            \n",
    "            round += 1\n",
    "            \n",
    "            if starting_hp_combo == last_round_starting_hp_combo: # if after this full round best combo hasn't moved, then can terminate\n",
    "                continue_tuning = 0\n",
    "        \n",
    "\n",
    "        # Display final information\n",
    "        self.view_best_combo_and_score()\n",
    "            \n",
    "    \n",
    "\n",
    "    def _eval_combo(self, df_building_dict, train_pred, val_pred, test_pred):\n",
    "\n",
    "        if self.clf_type == 'Regression':\n",
    "\n",
    "            train_score = val_score = test_score = train_rmse = val_rmse = test_rmse = train_mape = val_mape = test_mape = 0\n",
    "\n",
    "            try:\n",
    "                train_score = r2_score(self.train_y, train_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_score = r2_score(self.val_y, val_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_score = r2_score(self.test_y, test_pred)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                train_rmse = np.sqrt(mean_squared_error(self.train_y, train_pred))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_rmse = np.sqrt(mean_squared_error(self.val_y, val_pred))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_rmse = np.sqrt(mean_squared_error(self.test_y, test_pred))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if self.key_stats_only == False:\n",
    "                try:\n",
    "                    train_mape = mean_absolute_percentage_error(self.train_y, train_pred)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    val_mape = mean_absolute_percentage_error(self.val_y, val_pred)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    test_mape = mean_absolute_percentage_error(self.test_y, test_pred)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            df_building_dict['Train r2'] = [np.round(train_score, 6)]\n",
    "            df_building_dict['Val r2'] = [np.round(val_score, 6)]\n",
    "            df_building_dict['Test r2'] = [np.round(test_score, 6)]\n",
    "            df_building_dict['Train RMSE'] = [np.round(train_rmse, 6)]\n",
    "            df_building_dict['Val RMSE'] = [np.round(val_rmse, 6)]\n",
    "            df_building_dict['Test RMSE'] = [np.round(test_rmse, 6)]\n",
    "            \n",
    "            if self.key_stats_only == False:\n",
    "                df_building_dict['Train MAPE'] = [np.round(train_mape, 6)]\n",
    "                df_building_dict['Val MAPE'] = [np.round(val_mape, 6)]\n",
    "                df_building_dict['Test MAPE'] = [np.round(test_mape, 6)]\n",
    "\n",
    "        \n",
    "        elif self.clf_type == 'Classification':\n",
    "\n",
    "            train_score = val_score = test_score = train_bal_accu = val_bal_accu = test_bal_accu = train_f1 = val_f1 = test_f1 = \\\n",
    "                train_precision = val_precision = test_precision = train_recall = val_recall = test_recall = 0\n",
    "\n",
    "            try:    \n",
    "                train_score = accuracy_score(self.train_y, train_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_score = accuracy_score(self.val_y, val_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_score = accuracy_score(self.test_y, test_pred)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                train_bal_accu = balanced_accuracy_score(self.train_y, train_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_bal_accu = balanced_accuracy_score(self.val_y, val_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_bal_accu = balanced_accuracy_score(self.test_y, test_pred)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                train_f1 = f1_score(self.train_y, train_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_f1 = f1_score(self.val_y, val_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_f1 = f1_score(self.test_y, test_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                train_precision = precision_score(self.train_y, train_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_precision = precision_score(self.val_y, val_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_precision = precision_score(self.test_y, test_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                train_recall = recall_score(self.train_y, train_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_recall = recall_score(self.val_y, val_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_recall = recall_score(self.test_y, test_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            df_building_dict['Train accu'] = [np.round(train_score, 6)]\n",
    "            df_building_dict['Val accu'] = [np.round(val_score, 6)]\n",
    "            df_building_dict['Test accu'] = [np.round(test_score, 6)]\n",
    "            df_building_dict['Train balanced_accuracy'] = [np.round(train_bal_accu, 6)]\n",
    "            df_building_dict['Val balanced_accuracy'] = [np.round(val_bal_accu, 6)]\n",
    "            df_building_dict['Test balanced_accuracy'] = [np.round(test_bal_accu, 6)]\n",
    "            df_building_dict['Train f1'] = [np.round(train_f1, 6)]\n",
    "            df_building_dict['Val f1'] = [np.round(val_f1, 6)]\n",
    "            df_building_dict['Test f1'] = [np.round(test_f1, 6)]\n",
    "            df_building_dict['Train precision'] = [np.round(train_precision, 6)]\n",
    "            df_building_dict['Val precision'] = [np.round(val_precision, 6)]\n",
    "            df_building_dict['Test precision'] = [np.round(test_precision, 6)]\n",
    "            df_building_dict['Train recall'] = [np.round(train_recall, 6)]\n",
    "            df_building_dict['Val recall'] = [np.round(val_recall, 6)]\n",
    "            df_building_dict['Test recall'] = [np.round(test_recall, 6)]\n",
    "\n",
    "        return df_building_dict, val_score, test_score\n",
    "    \n",
    "\n",
    "\n",
    "    def _train_and_test_combo(self, combo):\n",
    "        \"\"\" Helper to train and test each combination as part of tune() \"\"\"\n",
    "\n",
    "        combo = tuple(combo)\n",
    "        \n",
    "        params = {self.hyperparameters[i]:self.parameter_choices[self.hyperparameters[i]][combo[i]] for i in range(len(self.hyperparameters))}\n",
    "        \n",
    "        \n",
    "        # initialise object\n",
    "        clf = self.model(**params)\n",
    "\n",
    "        start = time.time()\n",
    "        score_500 = clf.predict(self.data, 500)\n",
    "        \n",
    "\n",
    "        CV_score_list = []\n",
    "        for day in [250, 300, 350, 400, 450]:  \n",
    "            CV_score_list.append(clf.predict(self.data, day)) \n",
    "        cv_score = np.mean(CV_score_list)     \n",
    "        end = time.time()\n",
    "\n",
    "        val_score = cv_score\n",
    "\n",
    "        # build output dictionary and save result\n",
    "        df_building_dict = params\n",
    "        df_building_dict['Val r2'] = [val_score]\n",
    "        df_building_dict['score_500'] = [score_500]\n",
    "        df_building_dict['cv_score'] = [cv_score]\n",
    "\n",
    "\n",
    "        tmp = pd.DataFrame(df_building_dict)\n",
    "\n",
    "\n",
    "        self.tuning_result = pd.concat([self.tuning_result, tmp])\n",
    "        self.tuning_result.index = range(len(self.tuning_result))\n",
    "        self._save_tuning_result()\n",
    "\n",
    "        # update best score stats\n",
    "        if val_score > self.best_score: \n",
    "            self.best_score = val_score\n",
    "            self.best_clf = clf\n",
    "            self.best_combo = combo\n",
    "\n",
    "        # update internal governing DataFrames\n",
    "        self.checked[combo] = 1\n",
    "        self.result[combo] = val_score\n",
    "\n",
    "        self._up_to += 1\n",
    "\n",
    "        print(f'''Trained and Tested combination {self._up_to} of {self._total_combos}: {combo}, taking time {np.round(end-start, 4)} seconds to get score of {np.round(val_score,4)}\n",
    "        Current best combo: {self.best_combo} with val score {np.round(self.best_score, 4)}''')\n",
    "\n",
    "\n",
    "    def _check_already_trained_best_score(self, combo):\n",
    "        \"\"\" Helper for checking whether an already trained combo is best score \"\"\"\n",
    "        \n",
    "        combo = tuple(combo)\n",
    "        \n",
    "        # update best score stats\n",
    "        if self.result[combo] > self.best_score: \n",
    "            self.best_score = self.result[combo]\n",
    "            self.best_clf = None\n",
    "            print(f\"As new Best Combo {combo} was read in, best_clf is set to None\")\n",
    "            self.best_combo = combo\n",
    "\n",
    "        print(f'''Already Trained and Tested combination {combo}, which had val score of {np.round(self.result[combo],4)}\n",
    "        Current best combo: {self.best_combo} with val score {np.round(self.best_score, 4)}. \n",
    "        Has trained {self._up_to} of {self._total_combos} combinations so far''')\n",
    "\n",
    "\n",
    "\n",
    "    def _save_tuning_result(self):\n",
    "        \"\"\" Helper to export tuning result csv \"\"\"\n",
    "\n",
    "        tuning_result_saving_address_strip = self.tuning_result_saving_address.split('.csv')[0]\n",
    "\n",
    "        self.tuning_result.to_csv(f'{tuning_result_saving_address_strip}.csv', index=False)\n",
    "\n",
    "\n",
    "    \n",
    "    def view_best_combo_and_score(self):\n",
    "        \"\"\" View best combination and its validation score \"\"\"\n",
    "        \n",
    "        print('Max Score: \\n', self.best_score)\n",
    "\n",
    "        if self.clf_type == 'Classification':\n",
    "            max_val_id = self.tuning_result['Val accu'].idxmax()\n",
    "            print('Max Test Score: \\n', self.tuning_result.iloc[max_val_id]['Test accu'])\n",
    "            \n",
    "        elif self.clf_type == 'Regression':\n",
    "            max_val_id = self.tuning_result['Val r2'].idxmax()\n",
    "            print('Max Test Score: \\n', self.tuning_result.iloc[max_val_id]['Test r2'])\n",
    "\n",
    "        print('Max Combo Index: \\n', self.best_combo, 'out of', self.n_items, '(note best combo is 0-indexed)')\n",
    "\n",
    "        final_combo = {self.hyperparameters[i]:self.parameter_choices[self.hyperparameters[i]][self.best_combo[i]] for i in range(len(self.hyperparameters))}\n",
    "        print('Max Combo Hyperparamer Combination: \\n', final_combo)\n",
    "\n",
    "        if self._tune_features:\n",
    "            print('Max Combo Features: \\n', self._feature_combo_n_index_map[self.best_combo[-1]])\n",
    "\n",
    "        print('% Combos Checked:', int(sum(self.checked.reshape((np.prod(self.n_items))))), 'out of', np.prod(self.n_items), 'which is', f'{np.mean(self.checked).round(8)*100}%')\n",
    "\n",
    "    \n",
    "\n",
    "    def read_in_tuning_result_df(self, address): \n",
    "        \"\"\" Read in tuning result csv and read data into checked and result arrays \"\"\"\n",
    "\n",
    "        BOOL_MAP = {'1': True, '0': False, '1.0': True, '0.0': False, True: True, False: False, 'True': True, 'False': False, 1: True, 0: False, 1.0: True, 0.0: False}\n",
    "\n",
    "        if self.parameter_choices is None:\n",
    "            raise AttributeError(\"Missing parameter_choices to build _parameter_value_map_index, please run set_hyperparameters() first\")\n",
    "\n",
    "        if self.clf_type is None:\n",
    "            raise AttributeError('Missing clf_type. Please run .read_in_model() first.')\n",
    "\n",
    "        self.tuning_result = pd.read_csv(address)\n",
    "\n",
    "        self._up_to = 0\n",
    "\n",
    "        self._create_parameter_value_map_index()\n",
    "\n",
    "        # read DataFrame data into internal governing DataFrames of JiaoCheng\n",
    "        for row in self.tuning_result.iterrows():\n",
    "\n",
    "            try:\n",
    "                self._up_to += 1\n",
    "        \n",
    "                combo = list()\n",
    "                for hyperparam in self.hyperparameters:\n",
    "                    if hyperparam == 'features':\n",
    "                        \n",
    "                        # reverse two dicts\n",
    "                        index_n_feature_combo_map = {self._feature_combo_n_index_map[key]:key for key in self._feature_combo_n_index_map}\n",
    "                        # special input\n",
    "                        combo.append(index_n_feature_combo_map[tuple(self._str_to_list(row[1]['features']))])\n",
    "                        \n",
    "                    else:\n",
    "                        if type(self.parameter_choices[hyperparam][0]) is bool:\n",
    "                            combo.append(self._parameter_value_map_index[hyperparam][BOOL_MAP[row[1][hyperparam]]])\n",
    "                        else:\n",
    "                            combo.append(self._parameter_value_map_index[hyperparam][row[1][hyperparam]])\n",
    "\n",
    "                combo = tuple(combo)\n",
    "                \n",
    "                self.checked[combo] = 1\n",
    "                \n",
    "                if self.clf_type == 'Regression':\n",
    "                    self.result[combo] = row[1]['Val r2']\n",
    "                elif self.clf_type == 'Classification':\n",
    "                    self.result[combo] = row[1]['Val accu']\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error message: {str(e)}\")\n",
    "                print('Error Importing this Row:', row)\n",
    "\n",
    "        print(f\"Successfully read in tuning result of {len(self.tuning_result)} rows\")\n",
    "\n",
    "\n",
    "\n",
    "    def _str_to_list(self, string):\n",
    "        \"\"\" Helper to convert string to list\"\"\"\n",
    "\n",
    "        out = list()\n",
    "        for feature in string.split(', '):\n",
    "            out.append(feature.strip('[').strip(']').strip(\"'\"))\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "    \n",
    "    def _create_parameter_value_map_index(self):\n",
    "        \"\"\" Helper to create parameter-value index map \"\"\"\n",
    "\n",
    "        self._parameter_value_map_index = dict()\n",
    "        for key in self.parameter_choices.keys():\n",
    "            tmp = dict()\n",
    "            for i in range(len(self.parameter_choices[key])):\n",
    "                tmp[self.parameter_choices[key][i]] = i\n",
    "            self._parameter_value_map_index[key] = tmp\n",
    "    \n",
    "\n",
    "\n",
    "    def set_tuning_result_saving_address(self, address):\n",
    "        \"\"\" Read in where to save tuning object \"\"\"\n",
    "\n",
    "        self.tuning_result_saving_address = address\n",
    "        print('Successfully set tuning output address')\n",
    "\n",
    "\n",
    "    \n",
    "    def set_best_model_saving_address(self, address):\n",
    "        \"\"\" Read in where to save best model  \"\"\"\n",
    "\n",
    "        self.best_model_saving_address = address\n",
    "        print('Successfully set best model output address')\n",
    "\n",
    "    \n",
    "\n",
    "    def _save_best_model(self):\n",
    "        \"\"\" Helper to save best model as a pickle \"\"\"\n",
    "\n",
    "        best_model_saving_address_split = self.best_model_saving_address.split('.pickle')[0]\n",
    "\n",
    "        with open(f'{best_model_saving_address_split}.pickle', 'wb') as f:\n",
    "            pickle.dump(self.best_clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JiaoCheng Initialised\n",
      "Successfully read in model <class '__main__.TradingStrategy'>, which is a Regression model\n",
      "Successfully recorded hyperparameter choices\n",
      "Successfully set tuning output address\n"
     ]
    }
   ],
   "source": [
    "tuner = JiaoCheng()\n",
    "tuner.read_in_data(data)\n",
    "tuner.read_in_model(TradingStrategy, 'Regression')\n",
    "\n",
    "parameter_choices = {\n",
    "    'suspension_lookback': [5, 7, 9], \n",
    "    'sign_change_threshold': [0.5, 0.75], \n",
    "    'wrong_sign_threshold': [0.5, 0.75], \n",
    "    'suspension_days': [1, 2, 3, 4, 5], \n",
    "    'stop_loss_lookback': [1, 2, 3], \n",
    "    'stop_loss_size_factor': [0.25, 0.5, 1, 2], \n",
    "    'build_period': [10, 20]\n",
    "    \n",
    "}\n",
    "\n",
    "tuner.set_hyperparameters(parameter_choices)\n",
    "\n",
    "tuner.set_tuning_order(['suspension_lookback', 'sign_change_threshold', 'wrong_sign_threshold', 'suspension_days', 'stop_loss_lookback', 'stop_loss_size_factor', 'build_period'])\n",
    "\n",
    "tuner.set_hyperparameter_default_values({\n",
    "    'suspension_lookback': 5, \n",
    "    'sign_change_threshold': 0.75, \n",
    "    'wrong_sign_threshold': 0.75, \n",
    "    'suspension_days': 3,\n",
    "    'stop_loss_lookback': 2, \n",
    "    'stop_loss_size_factor': 0.5, \n",
    "    'build_period': 10\n",
    "\n",
    "})\n",
    "\n",
    "try:\n",
    "    tuner.read_in_tuning_result_df(f'./tuning/TradingStrategy_250.csv')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "tuner.set_tuning_result_saving_address('./tuning/TradingStrategy_250.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default combo: [0, 1, 1, 2, 1, 1, 0] \n",
      "\n",
      "\n",
      "ROUND 1\n",
      "\n",
      "Round 1 \n",
      "Hyperparameter: suspension_lookback (index: 0) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.tune()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
